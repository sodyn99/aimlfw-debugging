{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingjobName = 'qoe_test'    # Replace with the training job name you created\n",
    "epochs = 1\n",
    "version = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 13:29:30.719165: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-08-29 13:29:30.719292: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version\n",
      "1.24.4\n",
      "job name is:  qoe_test\n",
      "2024-08-29 13:29:33,182 | feature_store_sdk.py 85 get_features() |  DEBUG | \"pdcpBytesDl\" does not have empty space\n",
      "2024-08-29 13:29:33,183 | feature_store_sdk.py 85 get_features() |  DEBUG | \"pdcpBytesUl\" does not have empty space\n",
      "2024-08-29 13:29:33,184 | feature_store_sdk.py 127 build_fetch_query() |  DEBUG | Check Select query--> select \"pdcpBytesDl\", \"pdcpBytesUl\" from qoe_test ;\n",
      "2024-08-29 13:29:33,414 | feature_store_sdk.py 93 get_features() |  DEBUG | Non spaced pd  pdcpBytesDl pdcpBytesUl\n",
      "0         0.0         0.0\n",
      "1         0.0         0.0\n",
      "2         0.0         0.0\n",
      "3         0.0         0.0\n",
      "4         0.0         0.0\n",
      "2024-08-29 13:29:33,417 | feature_store_sdk.py 108 get_features() |  DEBUG | Select pipeline merged_df --> \n",
      "  pdcpBytesDl pdcpBytesUl\n",
      "0         0.0         0.0\n",
      "1         0.0         0.0\n",
      "2         0.0         0.0\n",
      "3         0.0         0.0\n",
      "4         0.0         0.0\n",
      "Dataframe:\n",
      "      pdcpBytesDl pdcpBytesUl\n",
      "0             0.0         0.0\n",
      "1             0.0         0.0\n",
      "2             0.0         0.0\n",
      "3             0.0         0.0\n",
      "4             0.0         0.0\n",
      "...           ...         ...\n",
      "40510         0.0         0.0\n",
      "40511         0.0         0.0\n",
      "40512         0.0         0.0\n",
      "40513         0.0         0.0\n",
      "40514         0.0         0.0\n",
      "\n",
      "[40515 rows x 2 columns]\n",
      "      pdcpBytesDl pdcpBytesUl\n",
      "0             0.0         0.0\n",
      "1             0.0         0.0\n",
      "2             0.0         0.0\n",
      "3             0.0         0.0\n",
      "4             0.0         0.0\n",
      "...           ...         ...\n",
      "40510         0.0         0.0\n",
      "40511         0.0         0.0\n",
      "40512         0.0         0.0\n",
      "40513         0.0         0.0\n",
      "40514         0.0         0.0\n",
      "\n",
      "[40515 rows x 2 columns]\n",
      "Previous Data Types are -->  pdcpBytesDl    object\n",
      "pdcpBytesUl    object\n",
      "dtype: object\n",
      "New Data Types are -->  pdcpBytesDl    float32\n",
      "pdcpBytesUl    float32\n",
      "dtype: object\n",
      "(40505, 10, 2)\n",
      "(40505, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 13:29:33.493324: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-08-29 13:29:33.493350: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-08-29 13:29:33.493364: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (debug-pod): /proc/driver/nvidia/version does not exist\n",
      "2024-08-29 13:29:33.495050: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 10, 150)           91800     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 10, 150)           180600    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 150)               180600    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 302       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 453,302\n",
      "Trainable params: 453,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3241/3241 [==============================] - 72s 22ms/step - loss: 768909.6250 - mse: 768909.6250 - val_loss: 745143.5000 - val_mse: 745143.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 13:31:01.933663: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fb22ebefbe0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fb234137b50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fb22e8a39a0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from numpy import array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten, Dropout, Activation\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import numpy as np\n",
    "print(\"numpy version\")\n",
    "print(np.__version__)\n",
    "import pandas as pd\n",
    "import os\n",
    "from featurestoresdk.feature_store_sdk import FeatureStoreSdk\n",
    "from modelmetricsdk.model_metrics_sdk import ModelMetricsSdk\n",
    "\n",
    "fs_sdk = FeatureStoreSdk()\n",
    "mm_sdk = ModelMetricsSdk()\n",
    "print(\"job name is: \", trainingjobName)\n",
    "features = fs_sdk.get_features(trainingjobName, ['pdcpBytesDl','pdcpBytesUl'])\n",
    "print(\"Dataframe:\")\n",
    "print(features)\n",
    "\n",
    "features_cellc2b2 = features\n",
    "print(features_cellc2b2)\n",
    "print('Previous Data Types are --> ', features_cellc2b2.dtypes)\n",
    "features_cellc2b2[\"pdcpBytesDl\"] = pd.to_numeric(features_cellc2b2[\"pdcpBytesDl\"], downcast=\"float\")\n",
    "features_cellc2b2[\"pdcpBytesUl\"] = pd.to_numeric(features_cellc2b2[\"pdcpBytesUl\"], downcast=\"float\")\n",
    "print('New Data Types are --> ', features_cellc2b2.dtypes)\n",
    "\n",
    "features_cellc2b2 = features_cellc2b2[['pdcpBytesDl', 'pdcpBytesUl']]\n",
    "\n",
    "def split_series(series, n_past, n_future):\n",
    "    X, y = list(), list()\n",
    "    for window_start in range(len(series)):\n",
    "        past_end = window_start + n_past\n",
    "        future_end = past_end + n_future\n",
    "        if future_end > len(series):\n",
    "            break\n",
    "        # slicing the past and future parts of the window\n",
    "        past, future = series[window_start:past_end, :], series[past_end:future_end, :]\n",
    "        X.append(past)\n",
    "        y.append(future)\n",
    "    return np.array(X), np.array(y)\n",
    "X, y = split_series(features_cellc2b2.values,10, 1)\n",
    "X = X.reshape((X.shape[0], X.shape[1],X.shape[2]))\n",
    "y = y.reshape((y.shape[0], y.shape[2]))\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units = 150, activation=\"tanh\" ,return_sequences = True, input_shape = (X.shape[1], X.shape[2])))\n",
    "\n",
    "model.add(LSTM(units = 150, return_sequences = True,activation=\"tanh\"))\n",
    "\n",
    "model.add(LSTM(units = 150,return_sequences = False,activation=\"tanh\" ))\n",
    "\n",
    "model.add((Dense(units = X.shape[2])))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['mse'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(X, y, batch_size=10,epochs=int(epochs), validation_split=0.2)\n",
    "yhat = model.predict(X, verbose = 0)\n",
    "\n",
    "\n",
    "xx = y\n",
    "yy = yhat\n",
    "model.save(\"./output\")\n",
    "import json\n",
    "data = {}\n",
    "data['metrics'] = []\n",
    "data['metrics'].append({'Accuracy': str(np.mean(np.absolute(np.asarray(xx)-np.asarray(yy))<5))})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aimlfw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
